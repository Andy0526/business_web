*************ReadMe**********
1.爬取部分
hexun.py是一个使用urllib，urllib2实现的简单爬虫；
首先抱歉的是，刚开始分析网页我看错了hexun网站原来在加载网页时就已经把所有数据载下来，只是部分hidden，结果我误以为要做页内的js事件触发，折腾了好多时间。。。粗心大意害死人

在这样已经加载完的情形下，就可以用urllib2比较简单的构造request，捕获response，然后进行解码，重编码，这里的代码没有采用先把网页源码保存在本地，再进行解析，而是直接线上解析了（主要考虑到当前任务待爬取的页面量比较小）

2.解析部分
使用了HTMLParser来做网页的解析，它工作的原理主要是从上至下访问网页的dom树，在每次碰到开始标签，结束标签，标签之间的文档会执行对应的handle函数，所以我们只要在自定义的parser类中定义好标志位，在满足某些条件后，就意味着当前到了我们想要抓取的数据的区域；
当然也可以使用正则表达式或者beautifulSoup来做；

3.题外话
如果真的碰到了需要页内调用js函数的需求，在代码末尾注释掉的代码里，包含了使用chrome_driver来模拟浏览器访问，获取网页内元素，模拟点击事件的代码；


有任何问题，欢迎交流
 林川杰；
